{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-04T10:56:47.724953Z",
     "start_time": "2025-11-04T10:56:47.667553Z"
    }
   },
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "from jaxtyping import Float, Int\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "import einops\n",
    "import numpy as np\n",
    "import circuitsvis as cv\n",
    "from IPython.display import display, HTML"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:58:33.325711Z",
     "start_time": "2025-11-04T10:56:48.891630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "gpt2 = GPT2LMHeadModel.from_pretrained(\"openai-community/gpt2\").to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "hooked_gpt2 = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False\n",
    ")"
   ],
   "id": "f19b2cd25ec3d943",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e68cabc47644489a6bf3d691f392101"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcb723a599b549b09809ed85b6a877de"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66089c0e990d462890aa10d99928f7d5"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1363068d382048f9ad77271fec6de412"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b3c170f354749d1ba93827e46ced172"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "effbdb1b010b4a4b8312a582fb926259"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "285415aece7f4d5483cdb35d9c534d45"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28b37bcbc30f4264a5999ae3b562a64f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e3cb63d54ce462283879c5e262888ba"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "111b7cf3ca6246a08482ee79f44f98ec"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81e68d261e774b1aac5d773ccbef0009"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae491b9285094a5aa60fd6e8d1fc8278"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cabff35028cb4896ac6f9bb758d1deca"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39e7d27cc4624f59b1fd2fa70a865bc5"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:58:33.579435Z",
     "start_time": "2025-11-04T10:58:33.566545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"The raccoon sat on the mat.\"\n",
    "token_ids = tokenizer.encode(text)\n",
    "print(f\"Token (ids): {token_ids}\")\n",
    "print(f\"Tokens (string): {tokenizer.tokenize(text)}\")\n",
    "print(f\"Text string: {tokenizer.decode(token_ids, skip_special_tokens=False)}\")\n",
    "print(f\"Stuff to input a model: {tokenizer(text, return_tensors='pt')}\")"
   ],
   "id": "8d5db27d080c2023",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token (ids): [464, 3444, 20912, 3332, 319, 262, 2603, 13]\n",
      "Tokens (string): ['The', 'Ġrac', 'coon', 'Ġsat', 'Ġon', 'Ġthe', 'Ġmat', '.']\n",
      "Text string: The raccoon sat on the mat.\n",
      "Stuff to input a model: {'input_ids': tensor([[  464,  3444, 20912,  3332,   319,   262,  2603,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:58:40.415615Z",
     "start_time": "2025-11-04T10:58:40.037449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Once upon a\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "    output_logits = gpt2(**input_ids)[\"logits\"]\n",
    "print(f\"Logits: {output_logits}\")\n",
    "print(f\"Logits shape: {output_logits.shape}\")"
   ],
   "id": "3e0fe5b9d7e28d3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[[ -34.5645,  -34.4082,  -38.3080,  ...,  -41.6997,  -39.7802,\n",
      "           -35.0521],\n",
      "         [ -84.7256,  -82.9326,  -87.0165,  ...,  -91.6668,  -86.2355,\n",
      "           -84.7094],\n",
      "         [-109.0798, -105.7259, -109.9115,  ..., -114.2847, -107.6933,\n",
      "          -105.3613]]])\n",
      "Logits shape: torch.Size([1, 3, 50257])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:58:40.968911Z",
     "start_time": "2025-11-04T10:58:40.954097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_probas = output_logits.softmax(dim=-1)\n",
    "print(f\"Probabilites over vocabulary: {output_probas}\")"
   ],
   "id": "7d8ea84e9909ac86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilites over vocabulary: tensor([[[8.9156e-04, 1.0424e-03, 2.1106e-05,  ..., 7.1022e-07,\n",
      "          4.8419e-06, 5.4752e-04],\n",
      "         [3.2892e-06, 1.9758e-05, 3.3276e-07,  ..., 3.1810e-09,\n",
      "          7.2670e-07, 3.3428e-06],\n",
      "         [4.0888e-07, 1.1700e-05, 1.7799e-07,  ..., 2.2447e-09,\n",
      "          1.6358e-06, 1.6848e-05]]])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:58:41.524819Z",
     "start_time": "2025-11-04T10:58:41.513948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "most_likely_next_tokens = tokenizer.batch_decode(output_logits.argmax(dim=-1)[0])\n",
    "print(list(zip(tokenizer.tokenize(text), most_likely_next_tokens)))"
   ],
   "id": "95574ac7a3cf596f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Once', ' the'), ('Ġupon', ' a'), ('Ġa', ' time')]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:58:42.131369Z",
     "start_time": "2025-11-04T10:58:42.121255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "next_token = output_logits[0, -1].argmax(dim=-1)\n",
    "next_char = tokenizer.decode(next_token)\n",
    "print(\n",
    "    \"The next token is:\", repr(next_char)\n",
    ")  # repr is to show special tokens and spaces\n",
    "print(\"How the sentence becomes: \", text + next_char)"
   ],
   "id": "40d43b1bdc5a8d56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next token is: ' time'\n",
      "How the sentence becomes:  Once upon a time\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T10:58:44.575716Z",
     "start_time": "2025-11-04T10:58:42.807146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize text\n",
    "text = \"Once upon a\"\n",
    "# Convert text to tensor format\n",
    "tokens = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "print(\"Generating text...\\n\")\n",
    "# Generate 10 characters iteratively\n",
    "for i in range(10):\n",
    "    with torch.inference_mode():\n",
    "        # Get model predictions\n",
    "        output_logits = gpt2(**tokens).logits\n",
    "        # Select the most likely next token\n",
    "        next_token = output_logits[0, -1].argmax(dim=-1)\n",
    "        # Decode the token to a character\n",
    "        next_char = tokenizer.decode(next_token)\n",
    "    # Display the sequence so far\n",
    "    current_text = tokenizer.decode(tokens[\"input_ids\"][0])  # Reconstruct the string\n",
    "    print(f\"Generation step {i + 1}:\")\n",
    "    print(f\"Sequence so far: {current_text!r}\")\n",
    "    print(f\"{tokens['input_ids'].shape[-1] + 1}th char = {next_char!r}\\n\")\n",
    "    # Append the new character and re-tokenize\n",
    "    text += next_char\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "print(\"Final text:\", text)"
   ],
   "id": "f4c0cfe7e24b97dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text...\n",
      "\n",
      "Generation step 1:\n",
      "Sequence so far: 'Once upon a'\n",
      "4th char = ' time'\n",
      "\n",
      "Generation step 2:\n",
      "Sequence so far: 'Once upon a time'\n",
      "5th char = ','\n",
      "\n",
      "Generation step 3:\n",
      "Sequence so far: 'Once upon a time,'\n",
      "6th char = ' the'\n",
      "\n",
      "Generation step 4:\n",
      "Sequence so far: 'Once upon a time, the'\n",
      "7th char = ' world'\n",
      "\n",
      "Generation step 5:\n",
      "Sequence so far: 'Once upon a time, the world'\n",
      "8th char = ' was'\n",
      "\n",
      "Generation step 6:\n",
      "Sequence so far: 'Once upon a time, the world was'\n",
      "9th char = ' a'\n",
      "\n",
      "Generation step 7:\n",
      "Sequence so far: 'Once upon a time, the world was a'\n",
      "10th char = ' place'\n",
      "\n",
      "Generation step 8:\n",
      "Sequence so far: 'Once upon a time, the world was a place'\n",
      "11th char = ' of'\n",
      "\n",
      "Generation step 9:\n",
      "Sequence so far: 'Once upon a time, the world was a place of'\n",
      "12th char = ' great'\n",
      "\n",
      "Generation step 10:\n",
      "Sequence so far: 'Once upon a time, the world was a place of great'\n",
      "13th char = ' beauty'\n",
      "\n",
      "Final text: Once upon a time, the world was a place of great beauty\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T11:01:34.264118Z",
     "start_time": "2025-11-04T11:01:33.764140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reference_text = \"Once upon a time, there was a fox who lived in a forest.\"\n",
    "tokens = hooked_gpt2.to_tokens(reference_text).to(device)\n",
    "logits, cache = hooked_gpt2.run_with_cache(tokens)\n",
    "html = cv.attention.attention_pattern(\n",
    "    tokens=hooked_gpt2.to_str_tokens(reference_text),\n",
    "    attention=cache[\"pattern\", 3][0][7],\n",
    ")\n",
    "styled_html = f\"\"\"\n",
    "<div style=\"width:800px; font-size:16px;\">\n",
    "    {html}\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(styled_html))"
   ],
   "id": "bfc3d3c13dc6f6bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "<div style=\"width:800px; font-size:16px;\">\n",
       "    <div id=\"circuits-vis-efbe3f2a-acb1\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPattern } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-efbe3f2a-acb1\",\n",
       "      AttentionPattern,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"Once\", \" upon\", \" a\", \" time\", \",\", \" there\", \" was\", \" a\", \" fox\", \" who\", \" lived\", \" in\", \" a\", \" forest\", \".\"], \"attention\": [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7876808643341064, 0.21231918036937714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5992210507392883, 0.24833811819553375, 0.15244083106517792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2967802584171295, 0.06938446313142776, 0.46222153306007385, 0.17161375284194946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3352857232093811, 0.0420658215880394, 0.2937639653682709, 0.2577078640460968, 0.07117666304111481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11801108717918396, 0.020908450707793236, 0.07792424410581589, 0.0904872864484787, 0.6225990056991577, 0.07006998360157013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17295871675014496, 0.04271798953413963, 0.028894543647766113, 0.024140464141964912, 0.415112167596817, 0.3006803095340729, 0.015495868399739265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5042949914932251, 0.014261415228247643, 0.017218800261616707, 0.005788084585219622, 0.05352829769253731, 0.1714247316122055, 0.08965705335140228, 0.1438266932964325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23178993165493011, 0.002089726272970438, 0.005951509345322847, 0.0004584105918183923, 0.04805513471364975, 0.10114522278308868, 0.09423016011714935, 0.3203883469104767, 0.19589148461818695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32499006390571594, 0.0022049902472645044, 0.0035725287161767483, 0.0021009945776313543, 0.02384461835026741, 0.05382946506142616, 0.03935812786221504, 0.17231975495815277, 0.23610374331474304, 0.1416756808757782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06337948888540268, 1.4286655641626567e-05, 2.250746729259845e-05, 6.312086043180898e-05, 0.0008094444056041539, 0.0007012549904175103, 0.0015572926495224237, 0.009965726174414158, 0.023253001272678375, 0.8893527388572693, 0.010881181806325912, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5446365475654602, 5.808904461446218e-05, 0.00013011880218982697, 0.00023981461708899587, 0.0008613231475465, 0.001611888175830245, 0.010681485757231712, 0.0024784032721072435, 0.012999745085835457, 0.2760637700557709, 0.08358535170555115, 0.06665340065956116, 0.0, 0.0, 0.0, 0.0], [0.2986801266670227, 1.2696766134467907e-05, 2.5678766178316437e-05, 4.643154898076318e-05, 0.0008937832899391651, 0.0007691120845265687, 0.0016731098294258118, 0.0021424947772175074, 0.004385331645607948, 0.13578906655311584, 0.08339673280715942, 0.33452707529067993, 0.13765843212604523, 0.0, 0.0, 0.0], [0.23188234865665436, 8.756606803217437e-06, 3.1033679988468066e-05, 9.260947081202175e-06, 0.0006851288489997387, 0.0005689551471732557, 0.0006093255360610783, 0.002576342551037669, 0.0008215103298425674, 0.045046448707580566, 0.04863954335451126, 0.4812140464782715, 0.12078732997179031, 0.06711997836828232, 0.0, 0.0], [0.36265501379966736, 2.645804124767892e-05, 6.353930803015828e-05, 0.00012310240708757192, 0.0003816876851487905, 0.0014199444558471441, 0.0007294268580153584, 0.00340029108338058, 0.0036751925945281982, 0.019337208941578865, 0.05790450796484947, 0.15986797213554382, 0.12454954534769058, 0.16719679534435272, 0.0986693948507309, 0.0], [0.16244862973690033, 5.76701968384441e-05, 3.7081448681419715e-05, 5.697538654203527e-05, 0.00023817857436370105, 0.00019294084631837904, 0.0007151843747124076, 0.0018311268649995327, 0.0027580298483371735, 0.029682157561182976, 0.01515849307179451, 0.09902821481227875, 0.033597856760025024, 0.046845942735672, 0.461862176656723, 0.14548926055431366]]}\n",
       "    )\n",
       "    </script>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T11:02:55.974163Z",
     "start_time": "2025-11-04T11:02:55.961153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(gpt2)\n",
    "print(gpt2.config)"
   ],
   "id": "a45bd938eb8cce75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:18:16.559620Z",
     "start_time": "2025-11-04T12:18:16.546716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rand_float_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg).to(device)\n",
    "    random_input = torch.randn(shape).to(device)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    if isinstance(output, tuple):\n",
    "        output = output[0]\n",
    "    print(\"Output:\", output)\n",
    "    print(\"Output shape:\", output.shape, \"\\n\")\n",
    "\n",
    "\n",
    "def rand_int_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg).to(device)\n",
    "    random_input = torch.randint(100, 1000, shape).to(device)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    if isinstance(output, tuple):\n",
    "        output = output[0]\n",
    "    print(\"Output:\", output)\n",
    "    print(\"Output shape:\", output.shape, \"\\n\")"
   ],
   "id": "33786d77f0c2533e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T11:04:59.531652Z",
     "start_time": "2025-11-04T11:04:59.519685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sequence = \"Once upon a time, \"\n",
    "tokenized_sequence = tokenizer.tokenize(sequence)\n",
    "tokens = tokenizer(sequence, return_tensors=\"pt\").to(device)[\"input_ids\"]\n",
    "print(\"Tokenized sequence:\", tokenized_sequence)\n",
    "print(\"Token IDs:\", tokens)"
   ],
   "id": "6912bb5a8713bfc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sequence: ['Once', 'Ġupon', 'Ġa', 'Ġtime', ',', 'Ġ']\n",
      "Token IDs: tensor([[7454, 2402,  257,  640,   11,  220]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T11:05:05.224895Z",
     "start_time": "2025-11-04T11:05:05.214093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = 1  # starting with only one batch (thus 1 sentence)\n",
    "seq_len = len(tokenized_sequence)  # 6\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    n_ctx: int = gpt2.config.n_ctx  # 1024\n",
    "    d_model: int = gpt2.config.n_embd  # hidden size, or embedding dimension\n",
    "    n_heads: int = gpt2.config.n_head  # number of attention heads\n",
    "    n_layers: int = gpt2.config.n_layer  # number of transformer blocks\n",
    "    d_mlp: int = 4 * d_model  # MLP hidden size, 3072\n",
    "    d_head: int = d_model // n_heads  # dimension of each attention head, 64\n",
    "    layer_norm_eps: float = gpt2.config.layer_norm_epsilon  # layer norm epsilon\n",
    "    d_vocab: int = gpt2.config.vocab_size  # number of tokens in the vocabulary\n",
    "    init_range: float = (\n",
    "        gpt2.config.initializer_range\n",
    "    )  # initialization range for weights\n",
    "    debug: bool = True\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)"
   ],
   "id": "867e93629a7892d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(n_ctx=1024, d_model=768, n_heads=12, n_layers=12, d_mlp=3072, d_head=64, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, debug=True)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:18:24.807054Z",
     "start_time": "2025-11-04T12:18:24.067356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embed(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_E, std=cfg.init_range)\n",
    "\n",
    "    def forward(\n",
    "            self, int_tokens: Int[Tensor, \"batch seq_len\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        # just a mapping from int tokens to float vectors\n",
    "        return self.W_E[int_tokens]\n",
    "\n",
    "rand_int_test(Embed, [batch, seq_len])"
   ],
   "id": "280f46d9e42696fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6])\n",
      "Output: tensor([[[-0.0134, -0.0178, -0.0035,  ..., -0.0042,  0.0115,  0.0149],\n",
      "         [-0.0033, -0.0063,  0.0049,  ..., -0.0114,  0.0026,  0.0065],\n",
      "         [-0.0195, -0.0139,  0.0228,  ...,  0.0202, -0.0011, -0.0027],\n",
      "         [ 0.0449, -0.0042, -0.0135,  ..., -0.0188,  0.0015,  0.0049],\n",
      "         [-0.0134,  0.0182, -0.0066,  ..., -0.0381,  0.0009,  0.0242],\n",
      "         [ 0.0178, -0.0264,  0.0298,  ...,  0.0233,  0.0306,  0.0151]]],\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Output shape: torch.Size([1, 6, 768]) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:18:43.487765Z",
     "start_time": "2025-11-04T12:18:43.456913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_pos, std=cfg.init_range)\n",
    "\n",
    "    def forward(\n",
    "            self, int_tokens: Int[Tensor, \"batch seq_len\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        # take first seq_len learnt positional embeddings\n",
    "        return einops.repeat(\n",
    "            self.W_pos[:seq_len],\n",
    "            \"seq_len d_model -> batch seq_len d_model\",\n",
    "            batch=batch  # 1\n",
    "        )\n",
    "\n",
    "rand_int_test(PosEmbed, [batch, seq_len])"
   ],
   "id": "820f4d53898411f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6])\n",
      "Output: tensor([[[-1.5321e-02, -2.0440e-03,  8.6898e-03,  ...,  6.8708e-03,\n",
      "           1.7418e-02, -4.6864e-02],\n",
      "         [-1.0571e-02, -7.4795e-03,  3.4819e-02,  ..., -3.7164e-03,\n",
      "          -1.1367e-02, -3.4639e-02],\n",
      "         [ 5.8133e-03,  5.5778e-08,  8.6300e-03,  ..., -1.9935e-02,\n",
      "           1.6901e-02,  2.2116e-03],\n",
      "         [ 2.5371e-02,  1.2460e-02,  2.1821e-02,  ..., -6.7912e-03,\n",
      "          -1.0191e-02, -4.3987e-03],\n",
      "         [-2.1841e-02, -1.2428e-02,  9.4734e-03,  ...,  2.3605e-03,\n",
      "          -2.0820e-03,  4.8564e-03],\n",
      "         [-1.1437e-02,  1.5380e-02,  3.3769e-03,  ..., -7.8232e-04,\n",
      "           3.9412e-02, -3.0546e-03]]], grad_fn=<ExpandBackward0>)\n",
      "Output shape: torch.Size([1, 6, 768]) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:19:08.536511Z",
     "start_time": "2025-11-04T12:19:08.520003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.w = nn.Parameter(torch.empty(cfg.d_model))\n",
    "        self.b = nn.Parameter(torch.zeros(cfg.d_model))  # Bias!\n",
    "        nn.init.normal_(self.w, std=cfg.init_range)\n",
    "\n",
    "    def forward(\n",
    "            self, embedding: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        # compute mean\n",
    "        embedding_mean = embedding.mean(dim=-1, keepdim=True)\n",
    "        # compute standard deviation + eps\n",
    "        embedding_std = (embedding.var(dim=-1, keepdim=True, unbiased=False) + self.cfg.layer_norm_eps).sqrt()\n",
    "        # compute normalized embedding\n",
    "        embedding = (embedding - embedding_mean) / embedding_std\n",
    "        return embedding * self.w + self.b\n",
    "\n",
    "\n",
    "rand_float_test(LayerNorm, [batch, seq_len, cfg.d_model])"
   ],
   "id": "d7a385d29db2c4f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6, 768])\n",
      "Output: tensor([[[ 1.3315e-02, -4.1681e-04,  2.0928e-03,  ..., -4.7153e-04,\n",
      "          -4.5773e-03, -1.7275e-02],\n",
      "         [-4.6628e-03,  1.0136e-02,  5.6740e-03,  ..., -4.1052e-04,\n",
      "          -7.3222e-03,  3.3341e-02],\n",
      "         [ 1.3759e-02,  1.7675e-02,  7.0852e-03,  ..., -1.3318e-05,\n",
      "           1.3761e-02,  1.0174e-02],\n",
      "         [ 1.9054e-02,  2.1374e-03,  1.1312e-02,  ...,  2.5715e-04,\n",
      "           1.8823e-02,  3.3176e-03],\n",
      "         [ 1.1060e-03,  2.1896e-02, -5.5682e-03,  ...,  9.3507e-04,\n",
      "           1.1582e-02, -5.4541e-02],\n",
      "         [-1.0707e-02, -3.1679e-03,  2.1488e-02,  ..., -1.9208e-03,\n",
      "           1.8057e-02,  5.2587e-02]]], grad_fn=<AddBackward0>)\n",
      "Output shape: torch.Size([1, 6, 768]) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:20:00.443552Z",
     "start_time": "2025-11-04T12:20:00.384863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_K = nn.Parameter(torch.empty(cfg.n_heads, cfg.d_model, cfg.d_head))\n",
    "        self.b_K = nn.Parameter(torch.zeros(cfg.n_heads, cfg.d_head))\n",
    "        self.W_Q = nn.Parameter(torch.empty(cfg.n_heads, cfg.d_model, cfg.d_head))\n",
    "        self.b_Q = nn.Parameter(torch.zeros(cfg.n_heads, cfg.d_head))\n",
    "        self.W_V = nn.Parameter(torch.empty(cfg.n_heads, cfg.d_model, cfg.d_head))\n",
    "        self.b_V = nn.Parameter(torch.zeros(cfg.n_heads, cfg.d_head))\n",
    "        self.W_O = nn.Parameter(torch.empty(cfg.n_heads, cfg.d_head, cfg.d_model))\n",
    "        self.b_O = nn.Parameter(torch.zeros(cfg.d_model))\n",
    "\n",
    "        nn.init.normal_(self.W_K, std=cfg.init_range)\n",
    "        nn.init.normal_(self.W_Q, std=cfg.init_range)\n",
    "        nn.init.normal_(self.W_V, std=cfg.init_range)\n",
    "        nn.init.normal_(self.W_O, std=cfg.init_range)\n",
    "        self.mask = -1e4\n",
    "\n",
    "    def forward(\n",
    "            self, embedding: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        # compute K, Q, V projections\n",
    "        K = einops.einsum(\n",
    "            embedding,\n",
    "            self.W_K,\n",
    "            \"batch seq_len d_model, n_heads d_model d_head -> batch seq_len n_heads d_head\"\n",
    "        ) + self.b_K\n",
    "        Q = einops.einsum(\n",
    "            embedding,\n",
    "            self.W_Q,\n",
    "            \"batch seq_len d_model, n_heads d_model d_head -> batch seq_len n_heads d_head\"\n",
    "        ) + self.b_Q\n",
    "        V = einops.einsum(\n",
    "            embedding,\n",
    "            self.W_V,\n",
    "            \"batch seq_len d_model, n_heads d_model d_head -> batch seq_len n_heads d_head\"\n",
    "        ) + self.b_V\n",
    "        # compute attention scores\n",
    "        attention_scores = einops.einsum(\n",
    "            Q,\n",
    "            K,\n",
    "            \"batch dest_pos n_heads d_head, batch source_pos n_heads d_head -> batch n_heads dest_pos source_pos\"\n",
    "        )\n",
    "        # scale and mask attention scores (causal attention)\n",
    "        attention_scores = attention_scores / (self.cfg.d_head ** 0.5)\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "        attention_scores = attention_scores.masked_fill(mask, self.mask) # Masked positions should be close to 0, not actually 0\n",
    "        # softmax attention scores\n",
    "        attention_scores = attention_scores.softmax(dim=-1)\n",
    "        # compute weighted sum of values\n",
    "        z = einops.einsum(\n",
    "            V,\n",
    "            attention_scores,\n",
    "            \"batch seq_len n_heads d_head, batch n_heads dest_pos source_pos -> batch dest_pos n_heads d_head\"\n",
    "        )\n",
    "        # compute output projection\n",
    "        attn_output = einops.einsum(\n",
    "            z,\n",
    "            self.W_O,\n",
    "            \"batch seq_len n_heads d_head, n_heads d_head d_model -> batch seq_len d_model\"\n",
    "        ) + self.b_O\n",
    "        return attn_output\n",
    "\n",
    "rand_float_test(Attention, [batch, seq_len, cfg.d_model])"
   ],
   "id": "6af55e284945f7df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6, 768])\n",
      "Output: tensor([[[ 1.9943,  0.5804, -0.8176,  ...,  1.0229, -0.5229, -0.2109],\n",
      "         [ 1.9943,  0.5804, -0.8176,  ...,  1.0229, -0.5229, -0.2109],\n",
      "         [ 1.9943,  0.5804, -0.8176,  ...,  1.0229, -0.5229, -0.2109],\n",
      "         [ 1.9943,  0.5804, -0.8176,  ...,  1.0229, -0.5229, -0.2109],\n",
      "         [ 1.9943,  0.5804, -0.8176,  ...,  1.0229, -0.5229, -0.2109],\n",
      "         [ 1.9943,  0.5804, -0.8176,  ...,  1.0229, -0.5229, -0.2109]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Output shape: torch.Size([1, 6, 768]) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:20:39.275794Z",
     "start_time": "2025-11-04T12:20:39.198821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gelu_new(\n",
    "    input: Float[torch.Tensor, \"batch pos d_mlp\"],\n",
    ") -> Float[torch.Tensor, \"batch pos d_mlp\"]:\n",
    "    # Implementation of GeLU used by GPT2 - subtly different from PyTorch's\n",
    "    return (\n",
    "        0.5\n",
    "        * input\n",
    "        * (\n",
    "            1.0\n",
    "            + torch.tanh(\n",
    "                np.sqrt(2.0 / np.pi) * (input + 0.044715 * torch.pow(input, 3.0))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, cgf: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_in = nn.Parameter(torch.empty(cfg.d_model, cfg.d_mlp))\n",
    "        self.b_in = nn.Parameter(torch.zeros(cfg.d_mlp))\n",
    "        self.W_out = nn.Parameter(torch.empty(cfg.d_mlp, cfg.d_model))\n",
    "        self.b_out = nn.Parameter(torch.zeros(cfg.d_model))\n",
    "        nn.init.normal_(self.W_in, std=cfg.init_range)\n",
    "        nn.init.normal_(self.W_out, std=cfg.init_range)\n",
    "        self.activation = gelu_new\n",
    "\n",
    "    def forward(\n",
    "        self, embedding: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        # compute in projection\n",
    "        pre = einops.einsum(\n",
    "            embedding,\n",
    "            self.W_in,\n",
    "            \"batch seq_len d_model, d_model d_mlp -> batch seq_len d_mlp\"\n",
    "        ) + self.b_in\n",
    "        # apply activation\n",
    "        post = self.activation(pre)\n",
    "        # compute out projection\n",
    "        mlp_out = einops.einsum(\n",
    "            post,\n",
    "            self.W_out,\n",
    "            \"batch seq_len d_mlp, d_mlp d_model -> batch seq_len d_model\"\n",
    "        ) + self.b_out\n",
    "        return mlp_out\n",
    "\n",
    "rand_float_test(MLP, [batch, seq_len, cfg.d_model])"
   ],
   "id": "5e33f75d146f786e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6, 768])\n",
      "Output: tensor([[[-0.1366, -0.1738,  0.2074,  ..., -0.7421, -0.5898,  0.0689],\n",
      "         [-0.2110,  0.0263,  0.0598,  ..., -0.1454, -0.4640, -0.2758],\n",
      "         [ 0.0894, -0.5796, -0.0959,  ...,  0.0762,  0.1268,  0.2014],\n",
      "         [ 0.5708, -0.1968, -0.1139,  ...,  1.1255, -0.0080,  0.4017],\n",
      "         [ 0.2236, -0.2967, -0.2361,  ..., -0.2367, -0.0662, -0.2864],\n",
      "         [-0.0366,  0.3278,  0.0909,  ..., -0.1041, -0.1833,  0.2286]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Output shape: torch.Size([1, 6, 768]) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:20:46.410894Z",
     "start_time": "2025-11-04T12:20:46.302666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.ln1 = LayerNorm(cfg)\n",
    "        self.attn = Attention(cfg)\n",
    "        self.ln2 = LayerNorm(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "\n",
    "    def forward(\n",
    "        self, input_embedding: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        # normalize input\n",
    "        embedding = self.ln1(input_embedding)\n",
    "        # compute attention and add skip connection\n",
    "        mid_embedding = self.attn(embedding) + input_embedding\n",
    "        # normalize embedding\n",
    "        embedding = self.ln2(mid_embedding)\n",
    "        # compute MLP and add skip connection\n",
    "        output_embedding = self.mlp(embedding) + mid_embedding\n",
    "        # return output\n",
    "        return output_embedding\n",
    "\n",
    "rand_float_test(TransformerBlock, [batch, seq_len, cfg.d_model])"
   ],
   "id": "b816c2f7bc00073e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6, 768])\n",
      "Output: tensor([[[ 0.3258, -0.5019,  0.7033,  ..., -2.2886, -1.2654,  0.4554],\n",
      "         [-0.6707, -0.9330, -0.8344,  ..., -0.2078,  0.5639, -0.8845],\n",
      "         [ 1.1695, -0.5519,  0.3030,  ..., -1.8187,  0.7409, -0.7072],\n",
      "         [ 0.1526, -0.8722,  0.0598,  ...,  1.6024, -1.1545,  0.3237],\n",
      "         [-0.2018,  0.3114,  0.7507,  ...,  0.8845,  0.6824,  1.0461],\n",
      "         [ 0.2019, -0.9734,  0.4147,  ...,  1.3799, -1.1554,  1.5493]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Output shape: torch.Size([1, 6, 768]) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:20:54.586996Z",
     "start_time": "2025-11-04T12:20:53.920501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Unembed(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_U = nn.Parameter(torch.empty(cfg.d_model, cfg.d_vocab))\n",
    "        self.b_U = nn.Parameter(torch.zeros(cfg.d_vocab))\n",
    "        nn.init.normal_(self.W_U, std=cfg.init_range)\n",
    "\n",
    "    def forward(\n",
    "        self, embedding: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
    "        # compute logits\n",
    "        logits = einops.einsum(\n",
    "            embedding,\n",
    "            self.W_U,\n",
    "            \"batch seq_len d_model, d_model d_vocab -> batch seq_len d_vocab\"\n",
    "        ) + self.b_U\n",
    "        return logits\n",
    "\n",
    "rand_float_test(Unembed, [batch, seq_len, cfg.d_model])"
   ],
   "id": "4a09221c83b4498c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6, 768])\n",
      "Output: tensor([[[ 0.6935, -0.1383, -0.4351,  ..., -0.2934, -0.6750, -0.2848],\n",
      "         [-0.1704,  0.0941,  0.4547,  ..., -0.9353,  0.9911,  0.2873],\n",
      "         [ 0.1860,  0.4068, -0.0586,  ..., -0.0121,  0.2642, -0.9695],\n",
      "         [ 0.0307,  0.0652, -0.2422,  ...,  0.7824,  0.6268,  0.7185],\n",
      "         [-0.2772, -0.1581,  0.2110,  ..., -0.8265, -0.9453,  0.4571],\n",
      "         [ 0.0063, -1.4805,  0.6233,  ..., -0.4980,  0.0653,  0.2031]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Output shape: torch.Size([1, 6, 50257]) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:22:37.368937Z",
     "start_time": "2025-11-04T12:22:37.343261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.pos_embed = PosEmbed(cfg)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [TransformerBlock(cfg) for _ in range(cfg.n_layers)]\n",
    "        )\n",
    "        self.ln_final = LayerNorm(cfg)\n",
    "        self.unembed = Unembed(cfg)\n",
    "\n",
    "    def forward(\n",
    "        self, input_tokens: Int[Tensor, \"batch seq_len\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
    "        # compute embeddings + positional embeddings\n",
    "        embedding = self.embed(input_tokens) + self.pos_embed(input_tokens)\n",
    "        # compute transformer blocks outputs\n",
    "        for block in self.blocks:\n",
    "            embedding = block(embedding)\n",
    "        # normalize output\n",
    "        # compute logits\n",
    "        logits = self.unembed(self.ln_final(embedding))\n",
    "        return logits\n",
    "\n",
    "    def load_gpt2_weights(self, gpt2: GPT2LMHeadModel) -> None:\n",
    "        state_dict = {}\n",
    "\n",
    "        state_dict[\"embed.W_E\"] = gpt2.transformer.wte.weight\n",
    "        state_dict[\"pos_embed.W_pos\"] = gpt2.transformer.wpe.weight\n",
    "\n",
    "        for l in range(cfg.n_layers):\n",
    "            state_dict[f\"blocks.{l}.ln1.w\"] = gpt2.transformer.h[l].ln_1.weight\n",
    "            state_dict[f\"blocks.{l}.ln1.b\"] = gpt2.transformer.h[l].ln_1.bias\n",
    "\n",
    "            # In GPT-2, q,k,v are produced by one big linear map, whose output is\n",
    "            # concat([q, k, v])\n",
    "            W = gpt2.transformer.h[l].attn.c_attn.weight\n",
    "            W_Q, W_K, W_V = torch.tensor_split(W, 3, dim=1)\n",
    "            W_Q = einops.rearrange(W_Q, \"m (i h)->i m h\", i=cfg.n_heads)\n",
    "            W_K = einops.rearrange(W_K, \"m (i h)->i m h\", i=cfg.n_heads)\n",
    "            W_V = einops.rearrange(W_V, \"m (i h)->i m h\", i=cfg.n_heads)\n",
    "\n",
    "            state_dict[f\"blocks.{l}.attn.W_Q\"] = W_Q\n",
    "            state_dict[f\"blocks.{l}.attn.W_K\"] = W_K\n",
    "            state_dict[f\"blocks.{l}.attn.W_V\"] = W_V\n",
    "\n",
    "            qkv_bias = gpt2.transformer.h[l].attn.c_attn.bias\n",
    "            qkv_bias = einops.rearrange(\n",
    "                qkv_bias,\n",
    "                \"(qkv index head)->qkv index head\",\n",
    "                qkv=3,\n",
    "                index=cfg.n_heads,\n",
    "                head=cfg.d_head,\n",
    "            )\n",
    "            state_dict[f\"blocks.{l}.attn.b_Q\"] = qkv_bias[0]\n",
    "            state_dict[f\"blocks.{l}.attn.b_K\"] = qkv_bias[1]\n",
    "            state_dict[f\"blocks.{l}.attn.b_V\"] = qkv_bias[2]\n",
    "\n",
    "            W_O = gpt2.transformer.h[l].attn.c_proj.weight\n",
    "            W_O = einops.rearrange(W_O, \"(i h) m->i h m\", i=cfg.n_heads)\n",
    "            state_dict[f\"blocks.{l}.attn.W_O\"] = W_O\n",
    "            state_dict[f\"blocks.{l}.attn.b_O\"] = gpt2.transformer.h[l].attn.c_proj.bias\n",
    "\n",
    "            state_dict[f\"blocks.{l}.ln2.w\"] = gpt2.transformer.h[l].ln_2.weight\n",
    "            state_dict[f\"blocks.{l}.ln2.b\"] = gpt2.transformer.h[l].ln_2.bias\n",
    "\n",
    "            W_in = gpt2.transformer.h[l].mlp.c_fc.weight\n",
    "            state_dict[f\"blocks.{l}.mlp.W_in\"] = W_in\n",
    "            state_dict[f\"blocks.{l}.mlp.b_in\"] = gpt2.transformer.h[l].mlp.c_fc.bias\n",
    "\n",
    "            W_out = gpt2.transformer.h[l].mlp.c_proj.weight\n",
    "            state_dict[f\"blocks.{l}.mlp.W_out\"] = W_out\n",
    "            state_dict[f\"blocks.{l}.mlp.b_out\"] = gpt2.transformer.h[l].mlp.c_proj.bias\n",
    "        state_dict[\"unembed.W_U\"] = gpt2.lm_head.weight.T\n",
    "\n",
    "        state_dict[\"ln_final.w\"] = gpt2.transformer.ln_f.weight\n",
    "        state_dict[\"ln_final.b\"] = gpt2.transformer.ln_f.bias\n",
    "        self.load_state_dict(state_dict)"
   ],
   "id": "26bae7a105c60a1a",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:22:40.308611Z",
     "start_time": "2025-11-04T12:22:38.386953Z"
    }
   },
   "cell_type": "code",
   "source": "rand_int_test(GPT, [batch, seq_len])",
   "id": "c2d980db34e41344",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6])\n",
      "Output: tensor([[[ 1.5225e-02,  3.8826e-03, -1.1096e-02,  ...,  1.6017e-02,\n",
      "           1.3524e-02,  4.9619e-05],\n",
      "         [ 1.1275e-02,  4.5961e-03, -9.7187e-03,  ...,  1.5540e-02,\n",
      "           1.1435e-02,  2.0470e-03],\n",
      "         [ 1.2999e-02,  8.3015e-03, -1.4311e-02,  ...,  1.4610e-02,\n",
      "           1.4996e-02,  2.6185e-03],\n",
      "         [ 2.2296e-02, -1.4677e-03, -1.0998e-02,  ...,  1.8303e-02,\n",
      "           1.7340e-02,  1.4473e-03],\n",
      "         [ 1.4243e-02,  8.1804e-03, -7.1281e-03,  ...,  1.5325e-02,\n",
      "           9.9894e-03,  1.1718e-03],\n",
      "         [ 1.1972e-02,  4.0970e-03, -4.9842e-03,  ...,  1.3690e-02,\n",
      "           1.1461e-02,  3.1178e-03]]], grad_fn=<AddBackward0>)\n",
      "Output shape: torch.Size([1, 6, 50257]) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:22:43.209255Z",
     "start_time": "2025-11-04T12:22:41.515648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "demo_gpt2 = GPT(Config(debug=False)).to(device)\n",
    "# demo_gpt2.load_gpt2_weights(gpt2)\n",
    "demo_gpt2.load_state_dict(hooked_gpt2.state_dict(), strict=False)"
   ],
   "id": "9860636a7505071a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['blocks.0.attn.mask', 'blocks.0.attn.IGNORE', 'blocks.1.attn.mask', 'blocks.1.attn.IGNORE', 'blocks.2.attn.mask', 'blocks.2.attn.IGNORE', 'blocks.3.attn.mask', 'blocks.3.attn.IGNORE', 'blocks.4.attn.mask', 'blocks.4.attn.IGNORE', 'blocks.5.attn.mask', 'blocks.5.attn.IGNORE', 'blocks.6.attn.mask', 'blocks.6.attn.IGNORE', 'blocks.7.attn.mask', 'blocks.7.attn.IGNORE', 'blocks.8.attn.mask', 'blocks.8.attn.IGNORE', 'blocks.9.attn.mask', 'blocks.9.attn.IGNORE', 'blocks.10.attn.mask', 'blocks.10.attn.IGNORE', 'blocks.11.attn.mask', 'blocks.11.attn.IGNORE'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T12:22:43.960401Z",
     "start_time": "2025-11-04T12:22:43.749133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize text\n",
    "text = \"Once upon a\"\n",
    "# Convert text to tensor format\n",
    "tokens = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "print(\"Generating text...\\n\")\n",
    "# Generate 10 characters iteratively\n",
    "for i in range(20):\n",
    "    with torch.inference_mode():\n",
    "        # Get model predictions\n",
    "        output_logits = demo_gpt2(tokens[\"input_ids\"])\n",
    "        # Select the most likely next token\n",
    "        next_token = output_logits[0, -1].argmax(dim=-1)\n",
    "        # Decode the token to a character\n",
    "        next_char = tokenizer.decode(next_token)\n",
    "    # Display the sequence so far\n",
    "    current_text = tokenizer.decode(tokens[\"input_ids\"][0])  # Reconstruct the string\n",
    "    print(f\"Generation step {i+1}:\")\n",
    "    print(f\"Sequence so far: {current_text!r}\")\n",
    "    print(f\"{tokens['input_ids'].shape[-1]+1}th char = {next_char!r}\\n\")\n",
    "    # Append the new character and re-tokenize\n",
    "    text += next_char\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "print(\"Final text:\", text)"
   ],
   "id": "2a345991e0a6356e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text...\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[62]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m20\u001B[39m):\n\u001B[32m      8\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m torch.inference_mode():\n\u001B[32m      9\u001B[39m         \u001B[38;5;66;03m# Get model predictions\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m         output_logits = \u001B[43mdemo_gpt2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43minput_ids\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m         \u001B[38;5;66;03m# Select the most likely next token\u001B[39;00m\n\u001B[32m     12\u001B[39m         next_token = output_logits[\u001B[32m0\u001B[39m, -\u001B[32m1\u001B[39m].argmax(dim=-\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/code/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[59]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36mGPT.forward\u001B[39m\u001B[34m(self, input_tokens)\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m     14\u001B[39m     \u001B[38;5;28mself\u001B[39m, input_tokens: Int[Tensor, \u001B[33m\"\u001B[39m\u001B[33mbatch seq_len\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     15\u001B[39m ) -> Float[Tensor, \u001B[33m\"\u001B[39m\u001B[33mbatch seq_len d_vocab\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m     16\u001B[39m     \u001B[38;5;66;03m# compute embeddings + positional embeddings\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     embedding = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tokens\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpos_embed\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     18\u001B[39m     \u001B[38;5;66;03m# compute transformer blocks outputs\u001B[39;00m\n\u001B[32m     19\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.blocks:\n",
      "\u001B[31mRuntimeError\u001B[39m: The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 1"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d100357da680c9ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
